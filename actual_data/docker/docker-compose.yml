# =======================================================================
# Platform Name            demo-platform
# Platform Stack:          trivadis/platys-modern-data-platform
# Platform Stack Version:  1.15.0-preview
# =======================================================================
version: '3.5'
networks:
  default:
    name: demo-platform
# enforce some dependencies
# backward compatiblity to platform < 1.14.0
# enforce some dependencies
# Enable PostgreSQL or MySQL for MLflow server
services:
  #  ================================== Zookeeper ========================================== #
  zookeeper-1:
    image: confluentinc/cp-zookeeper:7.1.2
    container_name: zookeeper-1
    hostname: zookeeper-1
    labels:
      com.platys.name: zookeeper
    ports:
      - 2181:2181
    environment:
      ZOOKEEPER_SERVER_ID: 1
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_INIT_LIMIT: 5
      ZOOKEEPER_SYNC_LIMIT: 2
    volumes:
      - ./data-transfer:/data-transfer
    restart: unless-stopped
#  ================================== Kafka ========================================== #
  kafka-1:
    image: confluentinc/cp-kafka:7.1.2
    container_name: kafka-1
    hostname: kafka-1
    labels:
      com.platys.name: kafka
    depends_on:
      - zookeeper-1
    ports:
      - 9092:9092
      - 19092:19092
      - 29092:29092
      - 39092:39092
      - 9992:9992
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_BROKER_RACK: rack1
      KAFKA_INTER_BROKER_LISTENER_NAME: LISTENER_INTERNAL
      KAFKA_ZOOKEEPER_CONNECT: zookeeper-1:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: LISTENER_INTERNAL:PLAINTEXT,LISTENER_LOCAL:PLAINTEXT,LISTENER_DOCKERHOST:PLAINTEXT,LISTENER_EXTERNAL:PLAINTEXT
      KAFKA_LISTENERS: LISTENER_INTERNAL://kafka-1:19092,LISTENER_LOCAL://kafka-1:39092,LISTENER_DOCKERHOST://kafka-1:29092,LISTENER_EXTERNAL://kafka-1:9092
      KAFKA_ADVERTISED_LISTENERS: LISTENER_INTERNAL://kafka-1:19092,LISTENER_LOCAL://localhost:39092,LISTENER_DOCKERHOST://${DOCKER_HOST_IP:-127.0.0.1}:29092,LISTENER_EXTERNAL://${PUBLIC_IP:-127.0.0.1}:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      KAFKA_MESSAGE_TIMESTAMP_TYPE: CreateTime
      KAFKA_MIN_INSYNC_REPLICAS: 1
      KAFKA_DELETE_TOPIC_ENABLE: 'True'
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'False'
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 100
      KAFKA_JMX_PORT: 9992
      KAFKA_JMX_OPTS: -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.local.only=false -Dcom.sun.management.jmxremote.rmi.port=9992
      KAFKA_JMX_HOSTNAME: ${PUBLIC_IP:-127.0.0.1}
      KAFKA_LOG4J_ROOT_LOGLEVEL: INFO
      KAFKA_TOOLS_LOG4J_LOGLEVEL: INFO
    volumes:
      - ./data-transfer:/data-transfer
    restart: unless-stopped
  kafka-2:
    image: confluentinc/cp-kafka:7.1.2
    container_name: kafka-2
    hostname: kafka-2
    labels:
      com.platys.name: kafka
    depends_on:
      - zookeeper-1
    ports:
      - 9093:9093
      - 19093:19093
      - 29093:29093
      - 39093:39093
      - 9993:9993
    environment:
      KAFKA_BROKER_ID: 2
      KAFKA_BROKER_RACK: rack1
      KAFKA_INTER_BROKER_LISTENER_NAME: LISTENER_INTERNAL
      KAFKA_ZOOKEEPER_CONNECT: zookeeper-1:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: LISTENER_INTERNAL:PLAINTEXT,LISTENER_LOCAL:PLAINTEXT,LISTENER_DOCKERHOST:PLAINTEXT,LISTENER_EXTERNAL:PLAINTEXT
      KAFKA_LISTENERS: LISTENER_INTERNAL://kafka-2:19093,LISTENER_LOCAL://kafka-2:39093,LISTENER_DOCKERHOST://kafka-2:29093,LISTENER_EXTERNAL://kafka-2:9093
      KAFKA_ADVERTISED_LISTENERS: LISTENER_INTERNAL://kafka-2:19093,LISTENER_LOCAL://localhost:39093,LISTENER_DOCKERHOST://${DOCKER_HOST_IP:-127.0.0.1}:29093,LISTENER_EXTERNAL://${PUBLIC_IP:-127.0.0.1}:9093
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      KAFKA_MESSAGE_TIMESTAMP_TYPE: CreateTime
      KAFKA_MIN_INSYNC_REPLICAS: 1
      KAFKA_DELETE_TOPIC_ENABLE: 'True'
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'False'
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 100
      KAFKA_JMX_PORT: 9993
      KAFKA_JMX_OPTS: -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.local.only=false -Dcom.sun.management.jmxremote.rmi.port=9993
      KAFKA_JMX_HOSTNAME: ${PUBLIC_IP:-127.0.0.1}
      KAFKA_LOG4J_ROOT_LOGLEVEL: INFO
      KAFKA_TOOLS_LOG4J_LOGLEVEL: INFO
    volumes:
      - ./data-transfer:/data-transfer
    restart: unless-stopped
  kafka-3:
    image: confluentinc/cp-kafka:7.1.2
    container_name: kafka-3
    hostname: kafka-3
    labels:
      com.platys.name: kafka
    depends_on:
      - zookeeper-1
    ports:
      - 9094:9094
      - 19094:19094
      - 29094:29094
      - 39094:39094
      - 9994:9994
    environment:
      KAFKA_BROKER_ID: 3
      KAFKA_BROKER_RACK: rack1
      KAFKA_INTER_BROKER_LISTENER_NAME: LISTENER_INTERNAL
      KAFKA_ZOOKEEPER_CONNECT: zookeeper-1:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: LISTENER_INTERNAL:PLAINTEXT,LISTENER_LOCAL:PLAINTEXT,LISTENER_DOCKERHOST:PLAINTEXT,LISTENER_EXTERNAL:PLAINTEXT
      KAFKA_LISTENERS: LISTENER_INTERNAL://kafka-3:19094,LISTENER_LOCAL://kafka-3:39094,LISTENER_DOCKERHOST://kafka-3:29094,LISTENER_EXTERNAL://kafka-3:9094
      KAFKA_ADVERTISED_LISTENERS: LISTENER_INTERNAL://kafka-3:19094,LISTENER_LOCAL://localhost:39094,LISTENER_DOCKERHOST://${DOCKER_HOST_IP:-127.0.0.1}:29094,LISTENER_EXTERNAL://${PUBLIC_IP:-127.0.0.1}:9094
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      KAFKA_MESSAGE_TIMESTAMP_TYPE: CreateTime
      KAFKA_MIN_INSYNC_REPLICAS: 1
      KAFKA_DELETE_TOPIC_ENABLE: 'True'
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'False'
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 100
      KAFKA_JMX_PORT: 9994
      KAFKA_JMX_OPTS: -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.local.only=false -Dcom.sun.management.jmxremote.rmi.port=9994
      KAFKA_JMX_HOSTNAME: ${PUBLIC_IP:-127.0.0.1}
      KAFKA_LOG4J_ROOT_LOGLEVEL: INFO
      KAFKA_TOOLS_LOG4J_LOGLEVEL: INFO
    volumes:
      - ./data-transfer:/data-transfer
    restart: unless-stopped
  #  ================================== ksqlDB ========================================== #
  ksqldb-server-1:
    image: confluentinc/ksqldb-server:0.27.1
    hostname: ksqldb-server-1
    container_name: ksqldb-server-1
    labels:
      com.platys.name: ksqldb
      com.platys.restapi.title: ksqlDB Server REST API
      com.platys.restapi.url: http://${PUBLIC_IP}:8088
    ports:
      - 8088:8088
      - 1095:1095
    environment:
      #KSQL_LOG4J_OPTS: "-Dlog4j.configuration=file:/etc/ksqldb/log4j-rolling.properties"
      KSQL_LOG4J_LOGGERS: org.apache.kafka.connect.runtime.rest=WARN,org.reflections=ERROR
      KSQL_LOG4J_PROCESSING_LOG_BROKERLIST: kafka-1:19092,kafka-2:19093,kafka-3:19094
      KSQL_LOG4J_PROCESSING_LOG_TOPIC: ksql_processing_log
      KSQL_KSQL_LOGGING_PROCESSING_TOPIC_NAME: ksql_processing_log
      KSQL_KSQL_LOGGING_PROCESSING_TOPIC_REPLICATION_FACTOR: 1
      KSQL_KSQL_LOGGING_PROCESSING_ROWS_INCLUDE: 'true'
      KSQL_KSQL_LOGGING_PROCESSING_STREAM_AUTO_CREATE: 'true'
      KSQL_KSQL_LOGGING_PROCESSING_TOPIC_AUTO_CREATE: 'true'
      # For Demo purposes: improve resource utilization and avoid timeouts
      KSQL_KSQL_STREAMS_NUM_STREAM_THREADS: 1
      KSQL_PRODUCER_ENABLE_IDEMPOTENCE: 'true'
      KSQL_KSQL_PERSISTENCE_DEFAULT_FORMAT_KEY: KAFKA
      KSQL_APPLICATION_ID: ksqldb-cluster
      KSQL_KSQL_SERVICE_ID: ksqldb-cluster
      KSQL_HOST_NAME: ksqldb-server-1
      KSQL_LISTENERS: http://0.0.0.0:8088
      KSQL_BOOTSTRAP_SERVERS: kafka-1:19092,kafka-2:19093,kafka-3:19094
      KSQL_CACHE_MAX_BYTES_BUFFERING: 0
      KSQL_RESPONSE_HTTP_HEADERS_CONFIG: ''
      KSQL_KSQL_SCHEMA_REGISTRY_URL: http://schema-registry-1:8081
      KSQL_KSQL_INTERNAL_TOPIC_REPLICAS: 1
      KSQL_KSQL_SINK_REPLICAS: 1
      KSQL_KSQL_STREAMS_REPLICATION_FACTOR: 1
      KSQL_KSQL_QUERY_PULL_METRICS_ENABLED: 'true'
      KSQL_KSQL_HIDDEN_TOPICS: ^_.*,default_ksql_processing_log
      KSQL_KSQL_SUPPRESS_ENABLED: 'False'
      KSQL_KSQL_SUPPRESS_BUFFER_SIZE_BYTES: '-1'
      KSQL_KSQL_QUERY_PULL_TABLE_SCAN_ENABLED: 'False'
      KSQL_CONFIG_DIR: /etc/ksqldb
      KSQL_KSQL_EXTENSION_DIR: /etc/ksqldb/ext/
      KSQL_JMX_OPTS: -Djava.rmi.server.hostname=localhost -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=1095 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.rmi.port=1095
    volumes:
      - ./data-transfer:/data-transfer
      - ./plugins/ksqldb:/etc/ksqldb/ext
#      - ./conf/ksqldb/etc/log4j.properties:/etc/ksqldb/log4j.properties
      - ./plugins/kafka-connect/connectors:/etc/kafka-connect/addl-plugins
      - ./plugins/kafka-connect/jars:/etc/kafka-connect/jars
      - ./plugins/opentelemetry/agents:/otel
    restart: unless-stopped
  # Access the cli by running:
  # > docker exec -it ksqldb-cli ksql http://ksqldb-server-1:8088
  ksqldb-cli:
    image: confluentinc/ksqldb-cli:0.27.1
    container_name: ksqldb-cli
    hostname: ksqldb-cli
    labels:
      com.platys.name: ksqldb-cli
    depends_on:
      - ksqldb-server-1
    volumes:
      - ./data-transfer:/data-transfer
    entrypoint: /bin/sh
    tty: true
    restart: unless-stopped
  #  ================================== Confluent Schema Registry ========================================== #
  schema-registry-1:
    image: confluentinc/cp-schema-registry:7.1.2
    hostname: schema-registry-1
    container_name: schema-registry-1
    labels:
      com.platys.name: schema-registry
      com.platys.restapi.title: Schema Registry REST API
      com.platys.restapi.url: http://${PUBLIC_IP}:8081
    ports:
      - 8081:8081
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry-1
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: kafka-1:19092,kafka-2:19093,kafka-3:19094
      SCHEMA_REGISTRY_KAFKASTORE_SECURITY_PROTOCOL: PLAINTEXT
      SCHEMA_REGISTRY_GROUP_ID: schema-registry
      SCHEMA_REGISTRY_LEADER_ELIGIBILITY: 'True'
      SCHEMA_REGISTRY_MODE_MUTABILITY: 'True'
      SCHEMA_REGISTRY_SCHEMA_COMPATIBILITY_LEVEL: backward
      SCHEMA_REGISTRY_KAFKASTORE_TOPIC_REPLICATION_FACTOR: 1
      SCHEMA_REGISTRY_ACCESS_CONTROL_ALLOW_ORIGIN: '*'
      SCHEMA_REGISTRY_ACCESS_CONTROL_ALLOW_METHODS: GET,POST,PUT,OPTIONS
      SCHEMA_REGISTRY_LOG4J_ROOT_LOGLEVEL: info
      SCHEMA_REGISTRY_DEBUG: 'False'
    volumes:
      - ./data-transfer:/data-transfer
      - ./plugins/opentelemetry/agents:/otel
    restart: unless-stopped
  #  ================================== Apache Kafka HQ (AKHQ) ========================================== #
  akhq:
    image: tchiotludo/akhq:latest
    container_name: akhq
    hostname: akhq
    labels:
      com.platys.name: akhq
      com.platys.webui.title: Apache Kafka AQ UI
      com.platys.webui.url: http://${PUBLIC_IP}:28107
    ports:
      - 28107:8080
    environment:
      AKHQ_CONFIGURATION: |
        akhq:
          connections:
            docker-kafka-server:
              properties:
                bootstrap.servers: 'kafka-1:19092,kafka-2:19093,kafka-3:19094'
              schema-registry:
                url: "http://schema-registry-1:8081"
                type: "confluent"
    volumes:
      - ./data-transfer:/data-transfer
    restart: unless-stopped
  #  ================================== Zeppelin ========================================== #
  zeppelin:
    image: trivadis/apache-zeppelin:0.10.0-spark3.1.3-hadoop3.2
    container_name: zeppelin
    hostname: zeppelin
    labels:
      com.platys.name: zeppelin
      com.platys.webui.title: Apache Zeppelin UI
      com.platys.webui.url: http://${PUBLIC_IP}:28080
    ports:
      - 28080:8080
      - 6060:6060
      - 5050:5050
      - 4050-4054:4050-4054
    env_file:
      - ./conf/hadoop.env
    environment:
      SPARK_DEFAULTS_CONF_spark_jars_repositories:
      SPARK_DEFAULTS_CONF_spark_jars_packages:
      SPARK_DEFAULTS_CONF_spark_jars_excludes:
      SPARK_DEFAULTS_CONF_spark_jars:
      SPARK_DEFAULTS_CONF_spark_jars_ivySettings:
      SPARK_DEFAULTS_CONF_spark_sql_catalogImplementation: in-memory
      CORE_CONF_fs_defaultFS: file:///tmp
      SPARK_DEFAULTS_CONF_spark_sql_warehouse_dir: file:///hive/warehouse
      SPARK_DEFAULTS_CONF_spark_yarn_dist_files: /spark/conf/hive-site.xml
      SPARK_DEFAULTS_CONF_spark_driver_extraJavaOptions:
      SPARK_DEFAULTS_CONF_spark_executor_extraJavaOptions:
      ZEPPELIN_ADDR: 0.0.0.0
      ZEPPELIN_PORT: '8080'
      ZEPPELIN_MEM: -Xms1024m -Xmx1024m -XX:MaxMetaspaceSize=512m
      ZEPPELIN_INTERPRETER_CONNECT_TIMEOUT: 120000
      ZEPPELIN_INTERPRETER_DEP_MVNREPO: https://repo.maven.apache.org/maven2
      ZEPPELIN_ADMIN_USERNAME: admin
      ZEPPELIN_ADMIN_PASSWORD: changeme
      ZEPPELIN_USER_USERNAME: zeppelin
      ZEPPELIN_USER_PASSWORD: changeme
      # set spark-master for Zeppelin interpreter
      ZEPPELIN_SPARK_MASTER: spark://spark-master:7077
      ZEPPELIN_NOTEBOOK_DIR: notebook
      ZEPPELIN_NOTEBOOK_CRON_ENABLE: 'True'
      PYSPARK_PYTHON: python3
      SPARK_SUBMIT_OPTIONS: ' --conf spark.ui.port=4050 --conf spark.driver.host=zeppelin --conf spark.driver.port=5050 --conf spark.driver.bindAddress=0.0.0.0 --conf spark.blockManager.port=6060 --conf spark.driver.extraJavaOptions=-Dcom.amazonaws.services.s3.enableV4 --conf spark.executor.extraJavaOptions=-Dcom.amazonaws.services.s3.enableV4'
    volumes:
      - ./data-transfer:/data-transfer
      - ./plugins/spark/jars:/extra-jars
      - ./container-volume/spark/logs/:/var/log/spark/logs
      - ./conf/s3cfg:/root/.s3cfg.template
    restart: unless-stopped
  #  ================================== Cassandra ========================================== #
  cassandra-1:
    image: cassandra:3.11
    container_name: cassandra-1
    hostname: cassandra-1
    labels:
      com.platys.name: cassandra
    ports:
      - 29042:9042
      - 7199:7199
      - 9160:9160
    environment:
      - CASSANDRA_SEEDS=cassandra-1
      - CASSANDRA_CLUSTER_NAME="Test Cluster"
      - CASSANDRA_DC=se1
      - CASSANDRA_ENDPOINT_SNITCH=GossipingPropertyFileSnitch
      - LOCAL_JMX=no
    volumes:
      - ./data-transfer:/data-transfer
      - ./conf/cassandra/jmxremote.access:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/management/jmxremote.access
      - ./conf/cassandra/jmxremote.password:/etc/cassandra/jmxremote.password
    restart: unless-stopped
  cassandra-web:
    image: trivadis/cassandra-web
    container_name: cassandra-web
    hostname: cassandra-web
    labels:
      com.platys.name: cassandra
      com.platys.webui.title: Cassandra Web UI
      com.platys.webui.url: http://${PUBLIC_IP}:28120
    ports:
      - 28120:3000
    environment:
      - CASSANDRA_HOSTNAME=cassandra-1
      - CASSANDRA_PORT=9042
      - CASSANDRA_USERNAME=cassandra
      - CASSANDRA_PASSWORD=cassandra
    volumes:
      - ./data-transfer:/data-transfer
    restart: unless-stopped
  #  ================================== OpenSearch ========================================== #
  opensearch-1:
    image: opensearchproject/opensearch:2
    hostname: opensearch-1
    container_name: opensearch-1
    labels:
      com.platys.name: opensearch
      com.platys.restapi.title: OpenSearch REST API
      com.platys.restapi.url: http://${PUBLIC_IP}:29200
      com.platys.manual.step.msgs: sudo sysctl -w vm.max_map_count=262144
    ports:
      - 29200:9200
      - 29600:9600
    environment:
      - cluster.name=opensearch-cluster
      - node.name=opensearch-1
      - discovery.type=single-node
      - DISABLE_INSTALL_DEMO_CONFIG=true     # disables execution of install_demo_configuration.sh bundled with security plugin, which installs demo certificates and security configurations to OpenSearch
      - DISABLE_SECURITY_PLUGIN=true     #  disables security plugin entirely in OpenSearch by setting plugins.security.disabled: true in opensearch.yml
      - bootstrap.memory_lock=true   # along with the memlock settings below, disables swapping
      - OPENSEARCH_JAVA_OPTS=-Xms512m -Xmx512m   # minimum and maximum Java heap size, recommend setting both to 50% of system RAM
      - http.cors.enabled=true
      - http.cors.allow-origin="http://${DOCKER_HOST_IP}:28275,http://${PUBLIC_IP}:28275,http://dejavu:1358,http://dataplatform:28125,http://dataplatform:28125,http://${PUBLIC_IP}:28125,http://${DOCKER_HOST_IP}:28125,http://127.0.0.1:1358"
      - http.cors.allow-headers="X-Requested-With,X-Auth-Token,Content-Type,Content-Length,Authorization"
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536 # maximum number of open files for the OpenSearch user, set to at least 65536 on modern systems
        hard: 65536
    volumes:
      - ./data-transfer:/data-transfer
    restart: unless-stopped
  #  ================================== OpenSearch Dashboards ========================================== #
  opensearch-dashboards:
    image: opensearchproject/opensearch-dashboards:2
    hostname: opensearch-dashboards
    container_name: opensearch-dashboards
    labels:
      com.platys.name: opensearch-dashboards
      com.platys.webui.title: OpenSearch Dashboards
      com.platys.webui.url: http://${PUBLIC_IP}:5603
    ports:
      - 5603:5601
    expose:
      - '5601'
    environment:
      - OPENSEARCH_HOSTS=["http://opensearch-1:9200"]
      - DISABLE_SECURITY_DASHBOARDS_PLUGIN=true     # disables security dashboards plugin in OpenSearch Dashboards
    volumes:
      - ./data-transfer:/data-transfer
    restart: unless-stopped
  #  ================================== Wetty ========================================== #
  wetty:
    image: svenihoney/wetty:latest
    container_name: wetty
    hostname: wetty
    labels:
      com.platys.name: wetty
      com.platys.webui.title: WeTTY UI
      com.platys.webui.url: http://${PUBLIC_IP}:3001
    ports:
      - 3001:3000
    environment:
      - REMOTE_SSH_SERVER=${DOCKER_HOST_IP}
      - REMOTE_SSH_PORT=22
      - REMOTE_SSH_USER=
      - WETTY_PORT=3000
    volumes:
      - ./data-transfer:/data-transfer
    restart: unless-stopped
  #  ================================== markdown-viewer ========================================== #
  markdown-viewer:
    image: trivadis/markdown-web:latest
    container_name: markdown-viewer
    hostname: markdown-viewer
    labels:
      com.platys.name: markdown-viewer
      com.platys.webui.title: Markdown Viewer UI
      com.platys.webui.url: http://${PUBLIC_IP}:80
    ports:
      - 80:80
    volumes:
      - ./artefacts:/home/python/markdown
      - ./data-transfer:/data-transfer
    restart: unless-stopped
  markdown-renderer:
    image: trivadis/jinja2-renderer:latest
    container_name: markdown-renderer
    hostname: markdown-renderer
    labels:
      com.platys.name: markdown-renderer
    environment:
      USE_PUBLIC_IP: 'True'
      PUBLIC_IP: ${PUBLIC_IP}
      DOCKER_HOST_IP: ${DOCKER_HOST_IP}
      DATAPLATFORM_HOME: ${DATAPLATFORM_HOME}
      PLATYS_PLATFORM_NAME: demo-platform
      PLATYS_PLATFORM_STACK: trivadis/platys-modern-data-platform
      PLATYS_PLATFORM_STACK_VERSION: 1.15.0-preview
      PLATYS_COPY_COOKBOOK_DATA: 'True'
    volumes:
      - ./artefacts/templates:/templates
      - ./artefacts/templates:/scripts
      - .:/variables
      - ./artefacts:/output
      - ./data-transfer:/data-transfer
volumes:
  data-transfer-vol:
    name: data_transfer_vol
